{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Particle class from lecture with z-component added\n",
    "class Particle:\n",
    "    def __init__(self, x, y, z, vx, vy, vz, mass):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.vx = vx\n",
    "        self.vy = vy\n",
    "        self.vz = vz\n",
    "        self.mass = mass\n",
    "        \n",
    "    def update(self, Fx, Fy, dt):\n",
    "        self.vx = self.vx + Fx / self.mass * dt\n",
    "        self.vy = self.vy + Fy / self.mass * dt\n",
    "        self.x = self.x + self.vx * dt\n",
    "        self.y = self.y + self.vy * dt\n",
    "        \n",
    "    def pairwise_force(self, particle):\n",
    "        r2 = (self.x - particle.x)**2.0 + \\\n",
    "             (self.y - particle.y)**2.0\n",
    "        F_mag = -(G * particle.mass * self.mass)/r2\n",
    "        F_x = (self.x - particle.x)/r2**0.5 * F_mag\n",
    "        F_y = (self.y - particle.y)/r2**0.5 * F_mag\n",
    "        return (F_x, F_y)\n",
    "    def print_particle(self):\n",
    "        print(\"Position:\", self.x, \",\", self.y, \",\", self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Create random data\n",
    "import numpy as np\n",
    "n = 3\n",
    "particle_positions = np.random.uniform(-10, 10, size=(n, 3))\n",
    "particle_velocities = np.random.uniform(-1, 1, size=(n, 3))\n",
    "particle_masses = np.random.uniform(-5, 5, size=(n,1))\n",
    "\n",
    "# Write data to HDF5\n",
    "try:\n",
    "    data_file = h5py.File('dataset', 'w')\n",
    "except:\n",
    "    data_file = h5py.File('dataset', 'a')\n",
    "    \n",
    "data_file.create_dataset('particle_positions', data=particle_positions)\n",
    "data_file.create_dataset('particle_velocities', data=particle_velocities)\n",
    "data_file.create_dataset('particle_masses', data=particle_masses)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['particle_masses', 'particle_positions', 'particle_velocities']\n",
      "Position: -4.75995360875 , 6.17656608901 , -2.17973529783\n",
      "Position: -9.89577944637 , -9.13664946585 , 1.11083665295\n",
      "Position: 1.7221470745 , 4.20378957362 , -1.2263901448\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename = 'dataset'\n",
    "data_file = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % list(data_file.keys()))\n",
    "a_group_key = list(data_file.keys())[0]\n",
    "\n",
    "# Get the data\n",
    "positions = list(data_file['particle_positions'])\n",
    "velocities = list(data_file['particle_velocities'])\n",
    "masses = list(data_file['particle_masses'])\n",
    "\n",
    "#Build particles from HDF5 data and print \n",
    "for i in range (len(positions)):\n",
    "    particle = Particle(positions[i][0], positions[i][1], positions[i][2], \n",
    "                        velocities[i][0], velocities[i][1], velocities[i][2],\n",
    "                        masses[i])\n",
    "    particle.print_particle()\n",
    "    \n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
